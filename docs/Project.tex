%
% File acl2018.tex
%
%% Based on the style files for ACL-2017, with some changes, which were, in turn,
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2018}
\usepackage{times}
\usepackage{latexsym}
\usepackage{natbib}
\usepackage{url}

\defcitealias{the_logon_project}{\scshape The LOGON project}
\defcitealias{nltk}{\scshape NLTK}
\defcitealias{datamuse}{\scshape Datamuse API}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
\title{Pun and Multiple Meaning Detection}

\author{Chaim Schendowich \\
  300307659 \\
  {\tt chysch@gmail.com} \\\And
  Anna Sokolov \\
  306616178 \\
  {\tt nannasokolov@gmail.com} \\}

\date{}

\begin{document}

\maketitle
\small{
GitHub repository:

github.com/chysch/Phonetic-Pun-ishment}

\hfill

\begin{abstract}
Creative speakers tend occasionally to instill in their words puns and multiple meanings. When the multiple meaning arises from the sound of the words, namely is caused by saying sounds that can be interpreted as two or more different combinations of words which all make sense in the given context, it is called a homophonic pun. The intention of this project is detection of such puns in given sentences if they exist and indication if not.
\end{abstract}

\section{Introduction}

Joke detection is one of the hardest problems in the field of artificial intelligence. This is because a joke sometimes rely on not having a totally reasonable meaning, ambiguity in meaning, or exaggeration of reality. As some of these concepts are hard for a machine to recognize like a human mind does, since there is a large amount of data to be considered in order to be able to distinguish between what is a reasonable description of reality and what is not, this project attempts to tackle the ambiguity in meaning as a basis for a joke, and specifically a homophonic multiplicity. We aim to detect such sentences, that are considered as puns, based on their phonetic structure and the sentences that can be derived from it.

\section{Method}

In order to find homophonic multiplicity in a sentence we decided to break the project into four stages described below. The stages are in a logical order and are modular and the basic logic is relevant for many languages. There are various features, however, that work only in English, so some of the modules will need to be changed to allow other languages.

We padded the logical core with a variety of hyper-parameters controlled by a rule plain-text file which can be easily created and modified by the user. These will also be described below. The general idea of most of them is weakening the accuracy of the phonetic match to allow more positive results.

\subsection{Training}

The first stage is preparing a phonetic dictionary. We called this stage Training although it doesn't contain training in the traditional sense (Usually "Training" relates to creating data via statistical analysis). Instead, we take ready clean-text phonetic dictionaries in the CMU dictionary format and prepare our own set of two phonetic dictionaries: A Word-Phoneme dictionary (called Fore) and a Phoneme-Word dictionary (called Back).

This stage is very simple and technical since it only requires reading a set of files and outputting the relevant information into two files. There are however various improvements which can be achieved by applying small modifications to the information as shall be explained in the hyper-parameter section.

\subsection{Analyzing}

The second stage is translating the plain-text test sentences into phonemes. In this stage we simply translate the sentences word for word into phonemes. Since there are words with more than one way of translating, the output in this stage is a list of matches for each sentence.

Since puns don't always cover all the words of the sentence (they usually don't), we added functionality to control the amount translated for shorter running time in the next stages. 

\subsection{Synthesizing}

All the preparation done, the next stage is creating a list of new sentences that can be composed out of words that phonetically match the sets of phonemes created in the previous stage. 

To achieve this purpose we created a phoneme search tree with words for leaves that the path to each leaf is the phonemes that compose the word. With this tree the new sentences can easily be created with a simple deterministic recursive function that scans the original phoneme list and traverses the tree to retrieve words. For efficiency reasons we favored using a stack to which we add each relevant sentence beginning iteratively.

\subsection{Cleaning}

This stage is responsible for cleaning the output of the previous stage, as at this moment we have a long list of new sentences that match a given sentence. They may match this sentence phonetically, but their validity both syntactically and semantically should be tested and invalid sentences should be removed from the list. 


In order to test whether a sentence is valid semantically and syntactically we use some open-source tools. 

\subsubsection{Parsing tree}
In order to test whether a sentence is valid grammatically, we use one of two tools.
In case our 'Online Mode' is on, the 'Logon' tool \citepalias{the_logon_project} is used to parse a sentence to its derivation tree. This tool help us to indicate whether a sentence is syntactically valid, as in case it doesn't, it retrieves zero parsing trees for the sentence. In case our 'Online Mode' is off, we then use the NLTK library \citepalias{nltk} for python, that performs POS tagging of the sentence, and with its help we know whether the sentence is valid syntactically.
\subsubsection{Avoid uncommonly used words}
This filters all produced sentences that use valid English words that are unlikely to be used in an everyday sentence, like acronyms, prefixes, etc.
\subsubsection{Incorrectness intended?}
Sometimes a sentence may be invalid semantically but this incorrectness is a part of the intended pun. We wish to determine whether this is the case and avoid removing these kind of sentences. This is why we use the Datamuse tool \citepalias{datamuse} that helps us to determine whether the problematic word of the incorrect sentence is related to any other word in the original sentence. 


\subsection{Hyper-Parameters}

The rule file required by the user can be empty, but usually will contain values for the hyper-parameters controlling the project. Below the hyper-parameters are listed by name with a short description and motivation.

\subsubsection{Replace}

\subsubsection{WordNetFilter}

\subsubsection{Threshold}
An integer represents the maximal distance allowed between the length of a given sentence (i.e the number of words in the sentence) and the length of a sentence matched to it phonetically. The bigger this threshold, the stricter is the policy, and matches that differ from the original sentence are dissmissed.

\subsubsection{OnlineMode}
When 'OnlineMode' is on, the algorithms will use external sources that require active internet connection. This improves the results, but can also extend run-time significantly. Those online resources include the 'Logon' tool mentioned in section 2.4.1, and the 'Datamuse' tool mentioned in section 2.4.3. 
If the 'OnlineMode' os off, the use of the 'Logon' tool is replaced with the use of NLTK library for Python, and the 'Pun intended' feature from section 2.4.3 is not used.

\subsubsection{Sticky}

\subsubsection{StickyAddSkip}

\section{Results}
Our results are based on several tests we ran and evaluated, that consist of different puns, i.e., sentences that homophonically may be interpreted as sentences with a different meaning. We used short sentences, as well as long sentences, and sentences with a variety of different types of puns.


In order to evaluate the results, we used a gold file constructed by a human. The comparison between our parsed file and the gold file consisted of counting the false results (both false negatives and false positives), as well as comparing the length of the matches list retrieved by the test and by the gold file, for each sentence.


The tests conducted a relatively low rate of false negatives, which means that our model is capable of producing homophonic puns. However, there was a large amount of false positives, due to the lack of efficient and reliable way to filter sentences that do not make sense semantically.

\section{Related Works}

Although much work has been done on classification and detection of humor in general and puns in particular, we did not find written material on detection of homophonic puns.

\citet{yang_lavie_dyer_hovy_2015} searched for humor anchors in sentences and detected humor through them. They did not search for puns specifically rather semantically humorous constructs. Even though their emphasis was not puns it is important to note that the idea of working through anchors is definately relevant in this context - we used a similar idea in the Threshold hyper-parameter.

Various groups worked on pun detection and understanding. \citet{miller_gurevych_2015} used Word Sense Disambiguation (WSD) to find the meanings of puns in corpora of homographic puns with only two meanings and exactly one pun word per sentence. Later \citet{miller_hempelmann_gurevych_2017} also continued the research comparing various types of WSD to see which method has better success not only disambiguating the puns but also detecting their existance and locating them. Unfortunately, the restrictions they put on their research meant that they were not dealing with homophonic puns.

The closest study we found was done by \citet{jaech_koncel-kedziorski_ostendorf_2016}. They cited various people who classified types of puns and analyzed puns theoretically. Their research was into understanding homophonic puns in sentences where the locations of the puns were already given. Since we are more interested in detecting if a homophonic pun exists and where, that approach was also not enough.

\section{Conclusions and Future Work}

\subsection{Validate output sentences semantically}
This is a part of the Cleaning stage, that removes produced sentences that are invalid semantically or syntactically. As the syntax validation part is being covered with the help of parsing trees analysis, validating semantics of a sentence is a much more complicated task. A need for an efficient tool to detect whether a sentence makes sense, has gradually occurred in the fields of NLP in recent years. The use of statistical techniques is a popular approach and may be used in future work in order to improve the cleaning stage of our project.

% include your own bib file like this:
%\bibliographystyle{acl}
% \bibliography{acl2018}
\bibliography{ProjectBiblio}
\bibliographystyle{acl_natbib}

% \begin{thebibliography}{9}

% \bibitem{the_logon_project}
% The LOGON project - a Norwegian National initiative towards re-usable language technology for Norwegian – English Machine Translation
% \\ http://erg.delph-in.net/logon

% \bibitem{Datamuse}
% Datamuse API- a word-finding query engine for developers. 
% \\ http://www.datamuse.com/api/

% \end{thebibliography}

\end{document}
